import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from matplotlib.patches import Patch
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier




st.set_page_config(page_title="Vision g√©n√©rale", layout="wide")
st.title('Projet : Pr√©diction de diab√®te üë®‚Äç‚öïÔ∏èü©∫ü©∏')
st.header('Introduction')
texte_intro = """
Bienvenue sur notre application permettant de mieux comprendre notre projet sur la pr√©diction du diab√®te √† partir de la base de donn√©es Kaggle. 

Quel est le contexte mondial concernant le diab√®te de type 2 ? 

√Ä l‚Äô√©chelle mondiale, le diab√®te de type 2 repr√©sente aujourd‚Äôhui un enjeu majeur de sant√© publique. Selon l‚ÄôOrganisation mondiale de la sant√© (OMS), plus de 530 millions de personnes en sont atteintes, un chiffre en constante augmentation sous l‚Äôeffet du vieillissement de la population, de la s√©dentarit√© et d‚Äôune alimentation d√©s√©quilibr√©e. Cette pathologie chronique entra√Æne d‚Äôimportantes complications cardiovasculaires et m√©taboliques, mais aussi un co√ªt √©conomique et social √©lev√© pour les syst√®mes de sant√©. Dans ce contexte, l‚Äôutilisation de mod√®les pr√©dictifs bas√©s sur le machine learning appara√Æt comme une solution innovante pour anticiper les risques, am√©liorer la pr√©vention personnalis√©e et orienter les politiques de sant√© vers une prise en charge plus pr√©coce et cibl√©e. 

"""

Texte_obj_projet = """
L‚Äôobjectif de notre projet est de concevoir un mod√®le de pr√©diction du diab√®te √† partir de donn√©es m√©dicales et d√©mographiques issues d‚Äôun large √©chantillon de population. √Ä l‚Äôaide de mod√®les tels que la r√©gression logistique et le Random Forest Classifier, nous cherchons √† identifier les facteurs les plus d√©terminants (HbA1c, glucose, IMC, hypertension‚Ä¶) et √† estimer la probabilit√© de d√©velopper un diab√®te de type 2.  

Ce travail vise √† d√©montrer que l‚Äôanalyse de donn√©es massives peut devenir un outil d‚Äôaide √† la d√©cision fiable pour la pr√©vention et le d√©pistage pr√©coce du diab√®te, tout en contribuant √† une meilleure compr√©hension des corr√©lations entre modes de vie et sant√© m√©tabolique. 
"""
st.markdown(texte_intro)

st.header('Objectif du projet')
st.markdown(Texte_obj_projet)


st.header('Donn√©e trouv√©e')
texte_ori_donnee = """
Le jeu de donn√©es utilis√© provient d‚Äôune base publique (Kaggle) regroupant des informations m√©dicales et d√©mographiques de plusieurs milliers d‚Äôindividus, accompagn√©es de leur statut diab√©tique (positif ou n√©gatif). Il contient des variables cl√©s telles que l‚Äô√¢ge, le sexe, le BMI (indice de masse corporelle), la pression art√©rielle, la pr√©sence d‚Äôhypertension ou de maladies cardiaques, l‚Äôhistorique tabagique, ainsi que des param√®tres biologiques comme le taux d‚ÄôHbA1c et le niveau de glucose sanguin. Ces donn√©es constituent la base d‚Äôapprentissage pour les mod√®les de pr√©diction du diab√®te de type 2. 

Vous pouver y acc√©der via ce lien ci-dessous :

https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset/data
"""
st.markdown(texte_ori_donnee)
st.divider()

df = pd.read_csv('diabetes_prediction_dataset.csv')
st.header("Information sur notre DataFrame")
st.subheader("Vous pouvez trouver ci-dessous le DataFrame utilis√© pour l'entrainement de nos mod√®le ")

st.dataframe(df)

st.write("Vous avez ici la description du DataFrame :")
st.dataframe(df.describe())


st.subheader("Pr√©traitement des donn√©es")
texte_2="""
Les codes suivant nous ont permis d'enlever les lignes avec des valeurs manquantes ou non explicite et de transformer les variables textes en chiffres pour que les mod√®les puissent les prendres en compte :

df_1 = df[df["smoking_history"] != "No Info"]

df_2 = df_1[df_1["gender"] != "Other"]

df_2['gender']  = df_2 ["gender"].map({'Female': 0, 'Male': 1}) (codage des 2 variables)

valeurs_uniques_smoking = df_3['smoking_history'].unique()

df_3['smoking_history']  = df_3 ["smoking_history"].map({'never': 0, 'not current': 1, 'former': 2, 'ever': 2, 'current': 3})
   
"""
texte_traitement = """
Les principales √©tapes de pr√©traitement ont inclus : 

- La suppression des valeurs ‚ÄúNo Info‚Äù (notamment pour le tabagisme) 

- La conversion des variables cat√©gorielles en valeurs num√©riques (ex. : sexe, historique tabagique) 

- La v√©rification et la normalisation des variables quantitatives 

- L‚Äôanalyse des valeurs aberrantes via des boxplots 

- Puis une analyse exploratoire (EDA) pour identifier les tendances et les corr√©lations entre variables (ex. lien entre glucose, HbA1c et diab√®te). 

Ce nettoyage garantit la coh√©rence et la fiabilit√© du jeu de donn√©es avant mod√©lisation. 
"""
st.markdown(texte_traitement)

st.markdown(texte_2)

df_1 = df[df["smoking_history"] != "No Info"]


df_2 = df_1[df_1["gender"] != "Other"]
df_2['gender'] = df_2["gender"].map({'Female': 0, 'Male': 1})
df_3 = df_2.copy()

valeurs_uniques_smoking = df_3['smoking_history'].unique()

df_3['smoking_history'] = df_3["smoking_history"].map({'never': 0, 'not current': 1, 'former': 2, 'ever': 2, 'current': 3})
df_3

st.write("Info sur le DataFrame pr√©trait√© :")

st.dataframe(df_3.describe())
st.divider()



st.header("Analyse exploratoire : visualisations")

st.subheader('Analyse interactive des variables')
variables = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level','diabetes']
variable_select = st.selectbox('Choisissez une variable', variables)

st.write("S√©lectionnez la variable quantitative que vous voulez explorer :")


if st.checkbox('Afficher les analyses et graphiques'):
    st.write(f'Variable s√©lectionn√©e : **{variable_select}**')
    numeric_data = df_3.dropna(subset=[variable_select])
    col1, col2, col3 = st.columns(3)
    with col1:
        fig = px.histogram(numeric_data, x=variable_select, nbins=20, color_discrete_sequence=["mediumturquoise"])
        st.plotly_chart(fig, use_container_width=True)
    with col2:
        fig2 = px.box(numeric_data, y=variable_select, color_discrete_sequence=["orange"])
        st.plotly_chart(fig2, use_container_width=True)
    with col3:
        st.metric("Min", np.round(numeric_data[variable_select].min(), 3))
        st.metric("Max", np.round(numeric_data[variable_select].max(), 3))
        st.metric("Moyenne", np.round(numeric_data[variable_select].mean(), 3))


st.divider()

st.header ('Distribution en fonction du diab√®te')

st.subheader("Bo√Æte √† moustache en fonction du Diab√®te")

num_features = ["age", "bmi", "HbA1c_level", "blood_glucose_level"]
colors = {0: "steelblue", 1: "salmon"}
labels = {0: "No Diabetes", 1: "Diabetes"}

fig, axes = plt.subplots(2, 2, figsize=(12, 8))
axes = axes.flatten()
for ax, col in zip(axes, num_features):
    data_to_plot = [df_3[df_3["diabetes"] == d][col].dropna() for d in [0, 1]]
    bp = ax.boxplot(data_to_plot, patch_artist=True, widths=0.6)
    for patch, d in zip(bp['boxes'], [0, 1]):
        patch.set_facecolor(colors[d])
    ax.set_xticks([1, 2])
    ax.set_xticklabels([labels[0], labels[1]])
    ax.set_title(f"{col} par Statut de diab√®te")
    ax.set_ylabel(col)
fig.legend([Patch(facecolor=colors[0]), Patch(facecolor=colors[1])],
           labels.values(), loc="upper right", title="Statut de diab√®te")
plt.tight_layout()
st.pyplot(fig)

texte_3 = """
Nos 4 boxplots repr√©sentent la distribution des valeurs de diff√©rentes variables entre deux groupes‚ÄØ: personnes atteintes de diab√®te ("Diabetes") et personnes non atteintes ("No Diabetes").

Pour la variable "age" :
   
    - Les non-diab√©tiques couvrent toute la gamme d‚Äô√¢ges, avec une m√©diane plus basse.
   
    - Les personnes atteintes de diab√®te sont plus √¢g√©es en moyenne‚ÄØavec une m√©diane plus √©lev√©e, intervalle sup√©rieur, et moins de jeunes

Pour la variable "bmi" ou Indice de Masse Corporelle
   
    - les diab√©tiques ont un IMC sup√©rieur √† celui des non-diab√©tiques.

Pour la variable "HbA1c_level" ou l'H√©moglobine glyqu√©e :
   
    - Le groupe diab√©tique a un HbA1c plus haute et des valeurs maximales clairement sup√©rieures.
   
    - Cette variable peut donc √™tre tr√®s discriminante pour le diab√®te.

Pour la variable blood_glucose_level (Glyc√©mie) :
    
    - Les diab√©tiques pr√©sentent des taux de glyc√©mie nettement plus √©lev√©s.
    
    - La distribution pour les non-diab√©tiques est centr√©e sur des valeurs plus basses, avec moins de dispersion.
"""
st.markdown(texte_3)

# Histogramme mais je pense que √ßa serait pas utile √† afficher parce qu'on a la d√©j√† fais, vaut mieux tout de m√™me garder pour garder le code source
fig2, axarr = plt.subplots(2, 2, figsize=(10, 10))
sns.histplot(df_3.age, bins=20, ax=axarr[0,0], color="red")
sns.histplot(df_3.bmi, bins=20, ax=axarr[0,1], color="red")
sns.histplot(df_3.blood_glucose_level, bins=20, ax=axarr[1,0], color="red")
sns.histplot(df_3.HbA1c_level, bins=20, ax=axarr[1,1], color="red")
plt.tight_layout()


st.subheader("Matrice de corr√©lation entre les Inputs et le Output")
fig3, ax3 = plt.subplots(figsize=[10,5])
sns.heatmap(df_3.corr(), annot=True, fmt='.2f', ax=ax3, cmap='coolwarm')
ax3.set_title("Correlation Matrix", fontsize=20)
st.pyplot(fig3)

texte_4="""

"""

st.subheader("Distribution des personnes atteintes de diab√®te apr√®s les traitements effectu√©s")
fig4, ax = plt.subplots(1,2, figsize=(18,8))
df_3['diabetes'].value_counts().plot.pie(explode=[0,0.1], autopct = "%1.1f%%", ax=ax[0], shadow=True)
ax[0].set_title('target')
ax[0].set_ylabel('')
sns.countplot(x='diabetes', data=df_3, ax=ax[1])
ax[1].set_title('diabetes')
st.pyplot(fig4)
texte_5 = """
Dans l'ensemble nos donn√©es contiennent plus de 
"""


st.divider()

st.header("Pr√©paration des Input et Output")

texte_pred="""
Les donn√©es trait√©es ont √©t√© subdivis√©es pour avoir des jeux de donn√©es qui seront utilis√©s pour entrainer les deux mod√®les et des jeux de donn√©es pour comparer avec les Output des mod√®les.

Dans notre cas, les jeux de donn√©es ont √©t√© divis√©s en 80 % pour les mod√®les et 20 % pour la comparaison avec les mod√®les. La subdivision a √©t√© effectu√©e de mani√®re al√©atoire tout en tenant compte du pourcentage mention√© pr√©c√©demment.
"""
st.markdown(texte_pred)

# Split data
col_name = df_3.drop('diabetes', axis=1).columns[:]
x = df_3.loc[:, col_name]
y = df_3['diabetes']
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)





st.subheader("Visualisation des Input et Output")
X_train
st.dataframe(X_train.describe())
y_train
st.dataframe(y_train.describe())
X_test
st.dataframe(X_test.describe())
y_test
st.dataframe(y_test.describe())



log_reg = LogisticRegression()
rand_clf = RandomForestClassifier(criterion='entropy', max_depth=15, max_features=0.75, min_samples_leaf=2, min_samples_split=3, n_estimators=130)
models = [
    {'label': 'LR', 'model': log_reg},
    {'label': 'RF', 'model': rand_clf}
]

means_roc = []
means_accuracy = []

for m in models:
    model = m['model']
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    means_accuracy.append(100 * round(acc, 4))
    auc = roc_auc_score(y_test, y_pred)
    means_roc.append(100 * round(auc, 4))

st.header("Justification du choix des mod√®les")
texte_just = """
La "Logistic Regression" est tr√®s utile pour un probl√®me de classification binaire (diab√®te oui/non) et interpr√®te le risque en donnant une probabilit√© d'appartenance (Menard, 2002).  

De l'autre c√¥t√© le 'Random Forest Classifier" est un mod√®le non lin√©aire, c'est √† dire il capture les interactions entre variables, et permet de d√©finir l'importance des variables (Hasan et al., 2025).
Le Random Forest est un mod√®le d‚Äôensemble, bas√© sur de multiples arbres de d√©cision, et il est √©galement reconnu pour sa robustesse et sa fiabilit√© accrues par rapport √† d'autres m√©thodes d'apprentissage (Hasan et al., 2025). De plus, Kavakiotis et al. (2017) ont montr√© que Random Forest peut atteindre une excellente pr√©cision dans la pr√©diction du diab√®te.
Le Random Forest atteint ainsi des taux de pr√©cision √©lev√©s dans la pr√©diction de l'apparition du diab√®te  √† partir de donn√©es d√©mographiques, cliniques et li√©es au mode de vie, tout en fournissant un classement fiable de l‚Äôimportance des variables explicatives (telles que le glucose ou l‚ÄôIMC) (Alam et al., 2024).

Source :

- I. Kavakiotis,O. Tsave, A. Salifoglou,Nicos Maglaveras, I. Vlahavas,I. Chouvarda. (2017). Machine Learning and Data Mining Methods in Diabetes Research. Computational and Structural Biotechnology Journal. Volume 15, 2017, Pages 104-116. DOI : https://doi.org/10.1016/j.csbj.2016.12.005

- Hasan, Mahade & Yasmin, Farhana. (2025). Predicting Diabetes Using Machine Learning: A Comparative Study of Classifiers. DOI : 10.48550/arXiv.2505.07036.

- Alam, Md Ashraful & Sohel, Amir & Hasan, Kh & Islam, Mohammad. (2024). Machine Learning And Artificial Intelligence in Diabetes Prediction And Management: A Comprehensive Review of Models. Innovatech Engineering Journal. 1. 107-124. 10.70937/jnes.v1i01.41. 

- Menard S. (2002) Applied Logistic Regression Analysis. Sage Publications, Thousand Oaks.
"""
st.markdown(texte_just)

st.header("Performance des deux mod√®les")
st.write("Accuracy (%) LR et RF :", means_accuracy)
st.write("ROC-AUC (%) LR et RF :", means_roc)

# Barplot Streamlit
fig6, ax6 = plt.subplots(figsize=(5,5))
index = np.arange(len(models))
bar_width = 0.35
rects1 = ax6.bar(index, means_accuracy, bar_width,
                alpha=0.8, color='mediumpurple', label='Accuracy (%)')
rects2 = ax6.bar(index + bar_width, means_roc, bar_width,
                alpha=0.8, color='rebeccapurple', label='ROC-AUC (%)')
ax6.set_xlim([-1, 3])
ax6.set_ylim([0, 100])
ax6.set_title('Performance Evaluation - Diabetes Prediction', fontsize=12)
ax6.set_xticks(index + bar_width/2)
ax6.set_xticklabels(['LR', 'RF'], rotation=0, fontsize=12)
ax6.legend(loc="upper right", fontsize=10)
st.pyplot(fig6)

st.subheader("Evaluation du model LR")
st.text(classification_report(y_test, log_reg.predict(X_test)))
st.subheader("Evalutaion du RF")
st.text(classification_report(y_test, rand_clf.predict(X_test)))
st.write("Matrice de confusion LR :", confusion_matrix(y_test, log_reg.predict(X_test)))
st.write("Matrice de confusion RF :", confusion_matrix(y_test, rand_clf.predict(X_test)))

st.divider()

st.header("Importance des variables du mod√®le Random Forest")
feature_names = X_train.columns.tolist()
importances = pd.DataFrame({
    'Feature': feature_names,
    'Importance': rand_clf.feature_importances_
}).sort_values(by='Importance', ascending=False)


fig_imp_rf, ax = plt.subplots(figsize=(6, 4))
sns.barplot(x='Importance', y='Feature', data=importances, palette='viridis', ax=ax)
ax.set_xlabel("Importance dans le mod√®le")
ax.set_ylabel("Variable")
ax.set_title("Importance des variables (Random Forest)")
plt.tight_layout()

st.pyplot(fig_imp_rf)
st.divider()



st.header("Vous pouvez consulter notre notebook via ce lien üòâ")

texte_imp ="""
https://drive.google.com/file/d/1KS9aaKJ5Dr71udbvFlyXEhC1azMgBEt0/view?usp=sharing
"""
st.markdown(texte_imp)
st.divider()
st.set_page_config(page_title="Pr√©diction du diab√®te", layout="wide")
st.title("Application Pr√©diction Diab√®te üë©‚Äç‚öïÔ∏èüìù")

# ==== Charger les donn√©es et entrainer les mod√®les ====
@st.cache_data
def load_and_train():
    # Remplace par ton vrai csv si n√©cessaire
    df = pd.read_csv('diabetes_prediction_dataset.csv')

    df = df[df["smoking_history"] != "No Info"]
    df = df[df["gender"] != "Other"]
    df['gender'] = df["gender"].map({'Female': 0, 'Male': 1})
    df['smoking_history'] = df["smoking_history"].map({'never': 0, 'not current': 1, 'former': 2, 'ever': 2, 'current': 3})

    X = df[['gender','age','hypertension','heart_disease','smoking_history','bmi','HbA1c_level','blood_glucose_level']]
    y = df['diabetes']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    lr = LogisticRegression()
    rf = RandomForestClassifier(criterion = 'entropy', max_depth = 15, max_features = 0.75, min_samples_leaf = 2, min_samples_split = 3, n_estimators = 130)

    lr.fit(X_train, y_train)
    rf.fit(X_train, y_train)
    return lr, rf

logreg, randforest = load_and_train()

# Choix du mode d'entr√© des donn√©es
mode = st.radio("Mode d'entr√©e", ["Uploader un fichier CSV", "Remplir le formulaire manuellement"])

input_df = None

if mode == "Uploader un fichier CSV":
    uploaded_file = st.file_uploader("Choisis un fichier CSV contenant les colonnes requises :", type=["csv"])
    if uploaded_file is not None:
        df_input = pd.read_csv(uploaded_file)
        st.write("Aper√ßu des entr√©es :")
        st.dataframe(df_input)
        input_df = df_input

elif mode == "Remplir le formulaire manuellement":
    st.write("Remplis les informations pour un seul patient :")
    gender = st.selectbox("Genre", ["Homme", "Femme"])
    gender_num = 1 if gender == "Homme" else 0
    age = st.number_input("√Çge", min_value=1, max_value=120, value=30)
    hypertension = st.selectbox("Hypertension ?", ["Non", "Oui"])
    heart_disease = st.selectbox("Probl√®me cardiaque ?", ["Non", "Oui"])
    smoking = st.selectbox("Historique tabagique", ["never", "not current", "former", "ever", "current"])
    bmi = st.number_input("IMC", min_value=5.0, max_value=90.0, value=25.0)
    a1c = st.number_input("HbA1c", min_value=2.0, max_value=18.0, value=5.2)
    glucose = st.number_input("Glyc√©mie", min_value=30.0, max_value=600.0, value=100.0)

    input_df = pd.DataFrame({
        'gender': [gender_num],
        'age': [age],
        'hypertension': [1 if hypertension=="Oui" else 0],
        'heart_disease': [1 if heart_disease=="Oui" else 0],
        'smoking_history': [ {'never': 0, 'not current': 1, 'former': 2, 'ever': 2, 'current': 3}[smoking] ],
        'bmi': [bmi],
        'HbA1c_level': [a1c],
        'blood_glucose_level': [glucose]
    })

    st.write("Aper√ßu de votre saisie :")
    st.dataframe(input_df)

# ==== Pr√©diction ====
if input_df is not None and st.button("Pr√©dire le diab√®te"):
    pred_lr = logreg.predict(input_df)
    pred_rf = randforest.predict(input_df)
    st.success(f"**R√©gression logistique pr√©dit :** {'Diab√©tique' if pred_lr[0]==1 else 'Non diab√©tique'}")
    st.success(f"**Random Forest pr√©dit :** {'Diab√©tique' if pred_rf[0]==1 else 'Non diab√©tique'}")



